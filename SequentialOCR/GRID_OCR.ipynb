{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "GRID_OCR.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ANxI3vKhFSL6"
      },
      "source": [
        "# End-to-end Trainable Sequential Optical Character Recognition\n",
        "(This notebook can be run inside Colab)\n",
        "\n",
        "The problem is inspired by [How to train a Keras model to recognize text with variable length](https://www.dlology.com/blog/how-to-train-a-keras-model-to-recognize-variable-length-text/) and redefined as:\n",
        "\n",
        "* Given a video footage showing an image from left to right, recover the text sentence printed on the image. To simplify the problem, we assume the sentence is randomly drawn from the [GRID corpus](http://staffwww.dcs.shef.ac.uk/people/J.Barker/assets/cooke-2006-jasa-ecbf8f7ef7cb429e9621317bfc64a67002a4c465be3c1a3f6144eeed058ee634.pdf).\n",
        "* The sentence can appear anywhere on the image and hence any frame in the video.\n",
        "* The video frame width is smaller than any character width so that no frame captures a full character.\n",
        "* The video frame height is the same as the image height.\n",
        "* Sample from the video footage a sequence of image frames as input to the neural net. To make the problem difficult, we use a low sample rate such that no two neighbouring frames in the sampled sequence share common pixels and some pixels from the original image are never captured in the samples. \n",
        "\n",
        "![Problem definition by picture](https://raw.githubusercontent.com/liyinnbw/ML/master/SequentialOCR/problem.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mKBd1qs7IlYF"
      },
      "source": [
        "## Random Seed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zP8tzYBAIk-F",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "np.random.seed(17)\n",
        "random.seed(17)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5St8h8ybFWMj"
      },
      "source": [
        "## Image Generator\n",
        "For generating images containing random text sentences and noise."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EYxNTZb9FKDc",
        "outputId": "e237608f-76f5-4544-e2d0-9e1ffdd5c5be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        }
      },
      "source": [
        "!pip install cairocffi\n",
        "import cairocffi as cairo\n",
        "import numpy as np\n",
        "from scipy import ndimage\n",
        "import re\n",
        "# this creates larger \"blotches\" of noise which look\n",
        "# more realistic than just adding gaussian noise\n",
        "# assumes greyscale with pixels ranging from 0 to 1\n",
        "\n",
        "regex = r'^[a-z ]+$'\n",
        "\n",
        "def speckle(img):\n",
        "    severity = np.random.uniform(0, 0.6)\n",
        "    blur = ndimage.gaussian_filter(np.random.randn(*img.shape) * severity, 1)\n",
        "    img_speck = (img + blur)\n",
        "    img_speck[img_speck > 1] = 1\n",
        "    img_speck[img_speck <= 0] = 0\n",
        "    return img_speck\n",
        "\n",
        "\n",
        "# paints the string in a random location the bounding box\n",
        "# also uses a random font, a slight random rotation,\n",
        "# and a random amount of speckle noise\n",
        "\n",
        "def paint_text(text, w, h, rotate=False, ud=False, multi_fonts=False):\n",
        "    surface = cairo.ImageSurface(cairo.FORMAT_RGB24, w, h)\n",
        "    with cairo.Context(surface) as context:\n",
        "        context.set_source_rgb(1, 1, 1)  # White\n",
        "        context.paint()\n",
        "        # this font list works in CentOS 7\n",
        "        if multi_fonts:\n",
        "            fonts = ['Century Schoolbook', 'Courier', 'STIX', 'URW Chancery L', 'FreeMono']\n",
        "            context.select_font_face(np.random.choice(fonts), cairo.FONT_SLANT_NORMAL,\n",
        "                                     np.random.choice([cairo.FONT_WEIGHT_BOLD, cairo.FONT_WEIGHT_NORMAL]))\n",
        "        else:\n",
        "            context.select_font_face('Courier', cairo.FONT_SLANT_NORMAL, cairo.FONT_WEIGHT_BOLD)\n",
        "        context.set_font_size(25)\n",
        "        box = context.text_extents(text)\n",
        "        border_w_h = (4, 4)\n",
        "        if box[2] > (w - 2 * border_w_h[1]) or box[3] > (h - 2 * border_w_h[0]):\n",
        "            raise IOError('Could not fit string into image. Max char count is too large for given image width.')\n",
        "\n",
        "        # teach the RNN translational invariance by\n",
        "        # fitting text box randomly on canvas, with some room to rotate\n",
        "        max_shift_x = w - box[2] - border_w_h[0]\n",
        "        max_shift_y = h - box[3] - border_w_h[1]\n",
        "        top_left_x = np.random.randint(0, int(max_shift_x))\n",
        "        if ud:\n",
        "            top_left_y = np.random.randint(0, int(max_shift_y))\n",
        "        else:\n",
        "            top_left_y = h // 2\n",
        "        context.move_to(top_left_x - int(box[0]), top_left_y - int(box[1]))\n",
        "        context.set_source_rgb(0, 0, 0)\n",
        "        context.show_text(text)\n",
        "\n",
        "    buf = surface.get_data()\n",
        "    a = np.frombuffer(buf, np.uint8)\n",
        "    a.shape = (h, w, 4)\n",
        "    a = a[:, :, 0]  # grab single channel\n",
        "    a = a.astype(np.float32) / 255\n",
        "    a = np.expand_dims(a, 0)\n",
        "    if rotate:\n",
        "        a = image.random_rotation(a, 3 * (w - top_left_x) / w + 1)\n",
        "    a = speckle(a)\n",
        "\n",
        "    return a\n",
        "\n",
        "\n",
        "def shuffle_mats_or_lists(matrix_list, stop_ind=None):\n",
        "    ret = []\n",
        "    assert all([len(i) == len(matrix_list[0]) for i in matrix_list])\n",
        "    len_val = len(matrix_list[0])\n",
        "    if stop_ind is None:\n",
        "        stop_ind = len_val\n",
        "    assert stop_ind <= len_val\n",
        "\n",
        "    a = list(range(stop_ind))\n",
        "    np.random.shuffle(a)\n",
        "    a += list(range(stop_ind, len_val))\n",
        "    for mat in matrix_list:\n",
        "        if isinstance(mat, np.ndarray):\n",
        "            ret.append(mat[a])\n",
        "        elif isinstance(mat, list):\n",
        "            ret.append([mat[i] for i in a])\n",
        "        else:\n",
        "            raise TypeError('`shuffle_mats_or_lists` only supports '\n",
        "                            'numpy.array and list objects.')\n",
        "    return ret\n",
        "\n",
        "\n",
        "# Translation of characters to unique integer values\n",
        "def text_to_labels(text):\n",
        "    ret = []\n",
        "    for char in text:\n",
        "        ret.append(alphabet.find(char))\n",
        "    return ret\n",
        "\n",
        "\n",
        "# Reverse translation of numerical classes back to characters\n",
        "def labels_to_text(labels):\n",
        "    ret = []\n",
        "    for c in labels:\n",
        "        if c == len(alphabet):  # CTC Blank\n",
        "            ret.append(\"\")\n",
        "        else:\n",
        "            ret.append(alphabet[c])\n",
        "    return \"\".join(ret)\n",
        "\n",
        "\n",
        "# only a-z and space..probably not to difficult\n",
        "# to expand to uppercase and symbols\n",
        "\n",
        "def is_valid_str(in_str):\n",
        "    search = re.compile(regex, re.UNICODE).search\n",
        "    return bool(search(in_str))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting cairocffi\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f7/99/b3a2c6393563ccbe081ffcceb359ec27a6227792c5169604c1bd8128031a/cairocffi-1.1.0.tar.gz (68kB)\n",
            "\r\u001b[K     |████▊                           | 10kB 24.9MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 20kB 3.2MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 30kB 4.3MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 40kB 3.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 51kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 61kB 4.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 3.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from cairocffi) (1.13.2)\n",
            "Requirement already satisfied: setuptools>=39.2.0 in /usr/local/lib/python3.6/dist-packages (from cairocffi) (42.0.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=1.1.0->cairocffi) (2.19)\n",
            "Building wheels for collected packages: cairocffi\n",
            "  Building wheel for cairocffi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cairocffi: filename=cairocffi-1.1.0-cp36-none-any.whl size=88591 sha256=75aa1c55273b00f6c7fad3f7f3d4c7c9e8171000d850b9aad61e03f46d93200a\n",
            "  Stored in directory: /root/.cache/pip/wheels/11/5e/47/167d9dfd5fa5850dd0cd3db80afe6db46e620edec3419dce5a\n",
            "Successfully built cairocffi\n",
            "Installing collected packages: cairocffi\n",
            "Successfully installed cairocffi-1.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QXPNDwaZFjM2"
      },
      "source": [
        "## Batch Generator (With Curriculum)\n",
        "Load, preprocess and generate batches for training or testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "h6kI18RYFKDn",
        "outputId": "c7eb1103-cf74-41ba-ec1e-55578b56379d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83
        }
      },
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing import sequence\n",
        "from keras.callbacks import Callback\n",
        "\n",
        "class OCRBatchGenerator(Callback):\n",
        "    def __init__(self, texts, textlenmax, imageshape, splitframes, frameinterval, steps, shuffle = False, curriculum=None):\n",
        "        super(OCRBatchGenerator, self).__init__()\n",
        "        self.steps = steps\n",
        "        self.shuffle = shuffle\n",
        "        self.curriculum = curriculum\n",
        "        self.imageshape = imageshape\n",
        "        self.splitframes = splitframes\n",
        "        self.frameinterval = frameinterval\n",
        "        self.texts = texts\n",
        "        self.textlenmax = textlenmax\n",
        "        self.textlen = textlenmax if self.curriculum == None else self.curriculum[0]\n",
        "    \n",
        "    def str_to_label(self, string):\n",
        "        label = []\n",
        "        for char in string:\n",
        "            if char == ' ':\n",
        "                label.append(26)\n",
        "            else:\n",
        "                label.append(ord(char) - ord('a')) #ord return unicode integer\n",
        "        return label\n",
        "    \n",
        "    def next(self):\n",
        "        full_size = len(self.texts)\n",
        "        batch_size = int(full_size / self.steps + 0.5)\n",
        "        while True:\n",
        "            idxs = np.arange(full_size)\n",
        "            if self.shuffle:\n",
        "                np.random.shuffle(idxs)\n",
        "            for step in range(self.steps):\n",
        "                idx_start = step*batch_size\n",
        "                idx_end = idx_start+batch_size if step<self.steps-1 else full_size\n",
        "                idx_batch = idxs[idx_start:idx_end]\n",
        "                images = np.zeros((len(idx_batch), self.splitframes, self.imageshape[0],self.imageshape[1]//self.splitframes//self.frameinterval,self.imageshape[2]),dtype='float32')\n",
        "                images_len = np.full((len(idx_batch),1), fill_value=self.splitframes, dtype='int32')\n",
        "                labels = []\n",
        "                labels_len = []\n",
        "                labels_truth = []\n",
        "                for idx, textidx in enumerate(idx_batch):\n",
        "                    text = self.texts[textidx]\n",
        "                    text = text[:self.textlen] if len(text) > self.textlen else text\n",
        "                    image= paint_text(text, self.imageshape[1], self.imageshape[0], rotate=False, ud=True, multi_fonts=True).reshape(self.imageshape)\n",
        "                    image_split = np.array(np.split(image,self.splitframes*self.frameinterval,axis=1))[np.arange(0, self.splitframes*self.frameinterval, self.frameinterval)]\n",
        "                    images[idx] = image_split\n",
        "                    label = self.str_to_label(text)\n",
        "                    labels.append(label)\n",
        "                    labels_len.append(len(label))\n",
        "                    labels_truth.append(text)\n",
        "                labels = sequence.pad_sequences(labels, maxlen=self.textlenmax, dtype='int32', padding='post', truncating='post', value=-1)#self.blank_char) #return numpy array\n",
        "                labels_len = np.asarray(labels_len, dtype='int32').reshape(-1,1)\n",
        "                # normalize image (the given image is already in 0-1 range)\n",
        "                images = (images-0.5)*2\n",
        "                inputs = {\n",
        "                    'images': images,\n",
        "                    'labels': labels,\n",
        "                    'images_len': images_len,\n",
        "                    'labels_len': labels_len,\n",
        "                    'truth': labels_truth # not for training, validation/test only\n",
        "                }\n",
        "                outputs = {'ctc':np.zeros([images.shape[0]])} #dummy ground truth ctc value, not used but needed\n",
        "                yield (inputs, outputs)\n",
        "                \n",
        "    # curriculum learning by gradually increasing text length\n",
        "    def on_epoch_begin(self, epoch, logs={}):\n",
        "        if self.curriculum != None and epoch<len(self.curriculum):\n",
        "            self.textlen = self.curriculum[epoch]\n",
        "        else:\n",
        "            self.textlen = self.textlenmax\n",
        "            \n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        logs = logs or {}\n",
        "        logs['curriculum_text_len']=self.textlen"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vvpmsGWZF0np"
      },
      "source": [
        "## NetGenerator\n",
        "A generator similar to BatchGenerator but instead generate models. Each model is given a name and can be visualized in Tensorboard."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FhJEPANyFKD1",
        "outputId": "593cfa86-b4f7-43c5-d7d6-87c523f0f4d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        }
      },
      "source": [
        "import keras\n",
        "from keras import regularizers\n",
        "from keras import backend as K\n",
        "from keras import optimizers\n",
        "from keras import regularizers\n",
        "\n",
        "# !pip install keras-tcn\n",
        "# from tcn import TCN\n",
        "\n",
        "# !pip install tensorflow-addons >= 1.13.1\n",
        "import tensorflow as tf\n",
        "# import tensorflow_addons as tfa\n",
        "!pip install keras-self-attention\n",
        "from keras_self_attention import SeqSelfAttention\n",
        "\n",
        "class TemporalBlock(tf.layers.Layer):\n",
        "    def __init__(self, n_outputs, kernel_size, strides, dilation_rate, dropout=0.2, \n",
        "                 trainable=True, name=None, dtype=None, \n",
        "                 activity_regularizer=None, **kwargs):\n",
        "        super(TemporalBlock, self).__init__(\n",
        "            trainable=trainable, dtype=dtype,\n",
        "            activity_regularizer=activity_regularizer,\n",
        "            name=name, **kwargs\n",
        "        )        \n",
        "        self.dropout = dropout\n",
        "        self.n_outputs = n_outputs\n",
        "        self.conv1 = CausalConv1D(\n",
        "            n_outputs, kernel_size, strides=strides, \n",
        "            dilation_rate=dilation_rate, activation=tf.nn.relu, \n",
        "            name=\"conv1\")\n",
        "        self.conv2 = CausalConv1D(\n",
        "            n_outputs, kernel_size, strides=strides, \n",
        "            dilation_rate=dilation_rate, activation=tf.nn.relu, \n",
        "            name=\"conv2\")\n",
        "        self.down_sample = None\n",
        "    \n",
        "    def build(self, input_shape):\n",
        "        channel_dim = 2\n",
        "        self.dropout1 = tf.layers.Dropout(self.dropout, [tf.constant(1), tf.constant(1), tf.constant(self.n_outputs)])\n",
        "        self.dropout2 = tf.layers.Dropout(self.dropout, [tf.constant(1), tf.constant(1), tf.constant(self.n_outputs)])\n",
        "        if input_shape[channel_dim] != self.n_outputs:\n",
        "            # self.down_sample = tf.layers.Conv1D(\n",
        "            #     self.n_outputs, kernel_size=1, \n",
        "            #     activation=None, data_format=\"channels_last\", padding=\"valid\")\n",
        "            self.down_sample = tf.layers.Dense(self.n_outputs, activation=None)\n",
        "    \n",
        "    def call(self, inputs, training=True):\n",
        "        x = self.conv1(inputs)\n",
        "        x = tf.contrib.layers.layer_norm(x)\n",
        "        x = self.dropout1(x, training=training)\n",
        "        x = self.conv2(x)\n",
        "        x = tf.contrib.layers.layer_norm(x)\n",
        "        x = self.dropout2(x, training=training)\n",
        "        if self.down_sample is not None:\n",
        "            inputs = self.down_sample(inputs)\n",
        "        return tf.nn.relu(x + inputs)\n",
        "      \n",
        "      \n",
        "def ctc_lambda_func(args):\n",
        "  y_pred, pred_len, y_true, true_len = args\n",
        "\n",
        "  # the 2 is critical here since the first couple outputs of the RNN\n",
        "  # tend to be garbage:\n",
        "  offset = 0\n",
        "  y_pred = y_pred[:, offset:]\n",
        "  return K.ctc_batch_cost(y_true, y_pred, pred_len-offset, true_len)\n",
        "  \n",
        "class NetGenerator():\n",
        "  def __init__(self, input_shape, out_categories, label_len):\n",
        "    self.input_shape = input_shape\n",
        "    self.out_categories = out_categories\n",
        "    self.label_len = label_len\n",
        "  def next(self):\n",
        "\n",
        "    modelnames =[\n",
        "        'conv32-dense64-dense64-lr0.001',\n",
        "        'conv32-dense64-bigru64-lr0.0005',\n",
        "        'conv32-dense64-tcn64k2d32-lr0.001',\n",
        "        # 'conv32-dense64-bilstm-selfattension-lr0.001'\n",
        "    ]\n",
        "     \n",
        "    for idx, name in enumerate(modelnames):\n",
        "      \n",
        "        ################################################\n",
        "        # input layers\n",
        "        ################################################\n",
        "        # the name parameter of multiple inputs must match the dictionary key of input dict\n",
        "        images = keras.Input(name='images', shape=self.input_shape, dtype='float32' )\n",
        "        labels = keras.Input(name='labels', shape=[self.label_len], dtype='int32') \n",
        "        images_len = keras.Input(name='images_len', shape=[1], dtype='int32') # needed for ctc in tensor format\n",
        "        labels_len = keras.Input(name='labels_len', shape=[1], dtype='int32') # needed for ctc in tensor format\n",
        "        \n",
        "        ################################################\n",
        "        # common feature extraction layers\n",
        "        ################################################\n",
        "        x = keras.layers.ZeroPadding3D(padding=(1,2,2))(images) \n",
        "        x = keras.layers.Conv3D(32, (3, 5, 5), strides=(1,2,2))(x)\n",
        "        x = keras.layers.BatchNormalization()(x)\n",
        "        x = keras.layers.Activation('relu')(x)\n",
        "#         x = keras.layers.SpatialDropout3D(0.5)(x)\n",
        "        x = keras.layers.MaxPooling3D(pool_size=(1, 2, 2), strides=(1, 2, 2))(x)\n",
        "\n",
        "        x = keras.layers.TimeDistributed(keras.layers.Flatten())(x)\n",
        "        x = keras.layers.Dense(64)(x) #reduce feature size\n",
        "        \n",
        "        #################################################\n",
        "        # 4 different models\n",
        "        #################################################\n",
        "        learnrate = 0.001\n",
        "        if idx == 0:\n",
        "            # MLP model, feel free to add more layers\n",
        "            x = keras.layers.Dense(64)(x)\n",
        "        elif idx == 1:\n",
        "            learnrate = 0.0005\n",
        "            # bi-gru model, our experiment shows single bi-gru is not enough. \n",
        "            x = keras.layers.Bidirectional(keras.layers.GRU(64, return_sequences=True), merge_mode='sum')(x)\n",
        "        elif idx == 2:\n",
        "            # TCN ( caveat: not exactly following the paper )\n",
        "            # just make sure effective receptive field > input 74 frames\n",
        "            # receptive field = kernel_size x last_dilation = 3 x 32 = 96 > 74\n",
        "            x_skip= x\n",
        "            x = keras.layers.Conv1D(64, 3, dilation_rate=1, padding='causal')(x)\n",
        "            x = keras.layers.Lambda(tf.contrib.layers.layer_norm)(x)\n",
        "            x = keras.layers.Activation('relu')(x)\n",
        "\n",
        "            x = keras.layers.Conv1D(64, 3, dilation_rate=2, padding='causal')(x)\n",
        "            x = keras.layers.Lambda(tf.contrib.layers.layer_norm)(x)\n",
        "            x = keras.layers.Activation('relu')(x)\n",
        "            x = keras.layers.add([x_skip,x])\n",
        "            x_skip= x\n",
        "\n",
        "            x = keras.layers.Conv1D(64, 3, dilation_rate=4, padding='causal')(x)\n",
        "            x = keras.layers.Lambda(tf.contrib.layers.layer_norm)(x)\n",
        "            x = keras.layers.Activation('relu')(x)\n",
        "\n",
        "            x = keras.layers.Conv1D(64, 3, dilation_rate=8, padding='causal')(x)\n",
        "            x = keras.layers.Lambda(tf.contrib.layers.layer_norm)(x)\n",
        "            x = keras.layers.Activation('relu')(x)\n",
        "            x = keras.layers.add([x_skip,x])\n",
        "            x_skip= x\n",
        "\n",
        "            x = keras.layers.Conv1D(64, 3, dilation_rate=16, padding='causal')(x)\n",
        "            x = keras.layers.Lambda(tf.contrib.layers.layer_norm)(x)\n",
        "            x = keras.layers.Activation('relu')(x)\n",
        "\n",
        "            x = keras.layers.Conv1D(64, 3, dilation_rate=32, padding='causal')(x)\n",
        "            x = keras.layers.Lambda(tf.contrib.layers.layer_norm)(x)\n",
        "            x = keras.layers.Activation('relu')(x)\n",
        "            x = keras.layers.add([x_skip,x])\n",
        "        # elif idx == 3:\n",
        "        #     # bi-LSTM + selfattension\n",
        "        #     x = keras.layers.Bidirectional(keras.layers.LSTM(units=128,return_sequences=True), merge_mode='concat')(x)\n",
        "        #     x = SeqSelfAttention(attention_activation='sigmoid', attention_width=15, name='Attention')(x)\n",
        "        \n",
        "        #################################################\n",
        "        # common classification layers\n",
        "        #################################################\n",
        "        x = keras.layers.Dense(self.out_categories)(x)\n",
        "        x = keras.layers.BatchNormalization()(x)\n",
        "      \n",
        "        # categorical classification for each time step\n",
        "        image_label_pred = keras.layers.Activation('softmax', name='y_pred')(x) \n",
        "        \n",
        "        # ctc\n",
        "        # the output layer name must match the key in the output dict\n",
        "        ctc_loss = keras.layers.Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([image_label_pred, images_len, labels, labels_len])\n",
        "        \n",
        "        #################################################\n",
        "        # compile model\n",
        "        #################################################\n",
        "        model = keras.Model(inputs=[images, images_len, labels, labels_len], outputs=[ctc_loss])\n",
        "        model.compile(\n",
        "            # the loss calc occurs elsewhere, so use a dummy lambda func for the loss\n",
        "            loss={'ctc': lambda y_true, y_pred: y_pred},\n",
        "            optimizer=optimizers.Adam(lr=learnrate),\n",
        "        )\n",
        "        \n",
        "        #################################################\n",
        "        # test function to be called in statistial callback\n",
        "        #################################################\n",
        "        test_func = K.function(inputs=[images, labels, images_len, labels_len, K.learning_phase()], outputs=[image_label_pred, ctc_loss])\n",
        "        yield (name, model, test_func)\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras-self-attention\n",
            "  Downloading https://files.pythonhosted.org/packages/44/3e/eb1a7c7545eede073ceda2f5d78442b6cad33b5b750d7f0742866907c34b/keras-self-attention-0.42.0.tar.gz\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from keras-self-attention) (1.17.5)\n",
            "Requirement already satisfied: Keras in /usr/local/lib/python3.6/dist-packages (from keras-self-attention) (2.2.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras->keras-self-attention) (2.8.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-self-attention) (1.4.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-self-attention) (1.12.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras->keras-self-attention) (3.13)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-self-attention) (1.0.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-self-attention) (1.1.0)\n",
            "Building wheels for collected packages: keras-self-attention\n",
            "  Building wheel for keras-self-attention (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-self-attention: filename=keras_self_attention-0.42.0-cp36-none-any.whl size=17296 sha256=b39079b75d440d1880da84a30fc03e622ae497c18e9ffe004690b4ef9403001f\n",
            "  Stored in directory: /root/.cache/pip/wheels/7b/05/a0/99c0cf60d383f0494e10eca2b238ea98faca9a1fe03cac2894\n",
            "Successfully built keras-self-attention\n",
            "Installing collected packages: keras-self-attention\n",
            "Successfully installed keras-self-attention-0.42.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zYRUKdf9F7pJ"
      },
      "source": [
        "## Statistical Callback\n",
        "Code to do valiadation and log metrics at end of each epoch. It also saves some input image at current epoch for visual validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BhjKBqm8FKD5",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import Callback\n",
        "from keras import backend as K \n",
        "import editdistance \n",
        "from PIL import Image\n",
        "\n",
        "class StatCallback(Callback):       \n",
        "    def __init__(self, func, validation_generator, validation_steps):\n",
        "        super(StatCallback, self).__init__()\n",
        "        self.func=func\n",
        "        self.validation_generator=validation_generator\n",
        "        self.validation_steps=validation_steps\n",
        "        self.offset = 0\n",
        "        \n",
        "    #Calculation of WER with Levenshtein distance.\n",
        "    def wer(self, r, h):\n",
        "        # initialisation\n",
        "        d = np.zeros((len(r)+1)*(len(h)+1), dtype=np.uint8)\n",
        "        d = d.reshape((len(r)+1, len(h)+1))\n",
        "        for i in range(len(r)+1):\n",
        "            for j in range(len(h)+1):\n",
        "                if i == 0:\n",
        "                    d[0][j] = j\n",
        "                elif j == 0:\n",
        "                    d[i][0] = i\n",
        "        # computation\n",
        "        for i in range(1, len(r)+1):\n",
        "            for j in range(1, len(h)+1):\n",
        "                if r[i-1] == h[j-1]:\n",
        "                    d[i][j] = d[i-1][j-1]\n",
        "                else:\n",
        "                    substitution = d[i-1][j-1] + 1\n",
        "                    insertion    = d[i][j-1] + 1\n",
        "                    deletion     = d[i-1][j] + 1\n",
        "                    d[i][j] = min(substitution, insertion, deletion)\n",
        "        return d[len(r)][len(h)]\n",
        "    \n",
        "    def labels_to_str(self,labels,showblank=False):\n",
        "        outstr= ''\n",
        "        for c in labels:\n",
        "            if c >= 0 and c < 26:\n",
        "                outstr += chr(c + ord('a'))\n",
        "            elif c == 26:\n",
        "                outstr += ' '\n",
        "            else:\n",
        "                if showblank:\n",
        "                    outstr +='?'\n",
        "        return outstr\n",
        "    \n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        samples = 0\n",
        "        mean_norm_ed = 0.0\n",
        "        mean_ed = 0.0\n",
        "        word_count = 0\n",
        "        word_err_count = 0\n",
        "        sentence_err_count = 0\n",
        "        mean_loss = 0\n",
        "        steps = self.validation_steps\n",
        "        while steps > 0:\n",
        "            batch = next(self.validation_generator)[0]\n",
        "            # call test_func provided in NetGenerator\n",
        "            image_label_pred, ctc_loss = self.func([batch['images'],batch['labels'],batch['images_len'],batch['labels_len']])\n",
        "            # accumulate ctc loss\n",
        "            mean_loss+=np.sum(ctc_loss)\n",
        "            \n",
        "            sample_count = image_label_pred.shape[0]\n",
        "            frames_count = image_label_pred.shape[1]-self.offset\n",
        "            pred_categories = image_label_pred.shape[2]\n",
        "            # using tensorflow ctc decoder to decode label\n",
        "            y_pred = K.placeholder(shape=[sample_count,frames_count,pred_categories])\n",
        "            input_length = K.placeholder(shape=[sample_count])\n",
        "            input_length_value = np.full(shape=sample_count, fill_value=frames_count)\n",
        "            decoder = K.ctc_decode(y_pred, input_length, beam_width=3, greedy=True)\n",
        "            decoded = K.get_session().run(decoder, feed_dict={y_pred:image_label_pred[:,self.offset:], input_length: input_length_value})[0][0]\n",
        "            # convert label to string\n",
        "            raw_strs=[] # FOR DEBUG: highest probability label for all timesteps. show blank\n",
        "            decoded_strs = [] # collapsed string after ctc_decode and no blank\n",
        "            for j in range(sample_count):\n",
        "                rawstr = self.labels_to_str(np.argmax(image_label_pred[j],axis=1),showblank=True)\n",
        "                outstr = self.labels_to_str(decoded[j],showblank=False)\n",
        "                raw_strs.append(rawstr)\n",
        "                decoded_strs.append(outstr)\n",
        "\n",
        "            truth_strs = batch['truth']\n",
        "            for j in range(sample_count):\n",
        "                if j<1:\n",
        "                  input_img = (np.concatenate(batch['images'][j],axis=1)/2+0.5)*255\n",
        "                  input_img = Image.fromarray(np.uint8(input_img[:,:,0]))\n",
        "                  input_img.save(\"./log/{:03d}.png\".format(steps),\"png\")\n",
        "                  # print debug strings to get a sense of result\n",
        "                  print('step {:03d}, truth:[{}] decoded:[{}] raw:[{}]'.format(steps,truth_strs[j],decoded_strs[j],raw_strs[j]))\n",
        "                edit_dist = editdistance.eval(decoded_strs[j], truth_strs[j])\n",
        "\n",
        "                #sentence error\n",
        "                if edit_dist!=0:\n",
        "                    sentence_err_count += 1\n",
        "                #word error\n",
        "                truth_words = truth_strs[j].split()\n",
        "                decoded_words = decoded_strs[j].split()\n",
        "                word_count += len(truth_words)\n",
        "                word_err_count += self.wer(truth_words, decoded_words)\n",
        "\n",
        "                #edit distance\n",
        "                mean_ed += float(edit_dist)\n",
        "                mean_norm_ed += float(edit_dist) / len(batch['labels'][j])\n",
        "            samples += sample_count\n",
        "            steps -= 1\n",
        "        mean_norm_ed = mean_norm_ed / samples #the same as cer\n",
        "        mean_ed = mean_ed / samples\n",
        "        mean_ser = sentence_err_count / samples\n",
        "        mean_wer = word_err_count / word_count\n",
        "        mean_loss = mean_loss / samples\n",
        "        \n",
        "        print('VAL_LOSS=',mean_loss,'SER=',mean_ser,'WER=',mean_wer,'CER=',mean_norm_ed)\n",
        "        logs = logs or {}\n",
        "        logs['val_loss']=mean_loss\n",
        "        logs['cer'] = mean_norm_ed\n",
        "        logs['wer'] = mean_wer\n",
        "        logs['ser'] = mean_ser\n",
        "        \n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6T9jWsGYqONU"
      },
      "source": [
        "## Generate [GRID Corpus](http://staffwww.dcs.shef.ac.uk/people/J.Barker/assets/cooke-2006-jasa-ecbf8f7ef7cb429e9621317bfc64a67002a4c465be3c1a3f6144eeed058ee634.pdf)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pBk5eAMaGzXi",
        "outputId": "b70ead75-590f-4cbe-d0f0-000db16cfa42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "import random\n",
        "\n",
        "words_command = ['bin','lay','place','set']\n",
        "words_color = ['blue','green','red','white']\n",
        "words_preposition = ['at','by','in','which']\n",
        "words_letter =['a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','x','y','z']\n",
        "words_digit = ['zero','one','two','three','four','five','six','seven','eight','nine']\n",
        "words_adverb = ['again','now','please','soon']\n",
        "texts = []\n",
        "for command in words_command:\n",
        "  for color in words_color:\n",
        "    for preposition in words_preposition:\n",
        "      for letter in words_letter:\n",
        "        for digit in words_digit:\n",
        "          for adverb in words_adverb:\n",
        "            texts.append(' '.join([command,color,preposition,letter,digit,adverb]))\n",
        "\n",
        "random.shuffle(texts)\n",
        "print('<',texts[0],'>')\n",
        "\n",
        "character_sequence_len_max = 35\n",
        "\n",
        "# split to train, validation, test\n",
        "sample_count = len(texts)\n",
        "print('sample count:',sample_count)\n",
        "train_texts = texts[:9000]\n",
        "train_count = len(train_texts)\n",
        "print('train count:',train_count)\n",
        "validation_texts = texts[train_count:train_count+1000]\n",
        "validation_count = len(validation_texts)\n",
        "print('validation count:',validation_count)\n",
        "# test_texts = texts[train_count+validation_count:]\n",
        "# test_count = len(test_texts)\n",
        "# print('test count:', test_count)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "< place blue which k four please >\n",
            "sample count: 64000\n",
            "train count: 9000\n",
            "validation count: 1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Vd7wPiXIqW_g"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vJECxkvRLNbV",
        "outputId": "f854c79a-7e8b-4967-f15b-a5bae0fad5d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "!pip install tensorboardcolab\n",
        "from tensorboardcolab import TensorBoardColab, TensorBoardColabCallback\n",
        "\n",
        "tbc=TensorBoardColab(port=6007, graph_path='.', startup_waiting_time=8)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorboardcolab in /usr/local/lib/python3.6/dist-packages (0.0.22)\n",
            "Wait for 8 seconds...\n",
            "TensorBoard link:\n",
            "https://011f25b2.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jed1EpYzFKD_",
        "outputId": "99d7d7d4-9813-494f-c943-f6bd6d72d2f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
        "from keras import backend as K \n",
        "import tensorflow as tf\n",
        "\n",
        "print (keras.__version__)\n",
        "print (tf.__version__)\n",
        "\n",
        "# # limit GPU memory\n",
        "# config = tf.ConfigProto()\n",
        "# config.gpu_options.per_process_gpu_memory_fraction = 0.6\n",
        "# # config.gpu_options.allow_growth=True\n",
        "# K.tensorflow_backend.set_session(tf.Session(config=config))\n",
        "\n",
        "\n",
        "image_shape = (50,740,1) \n",
        "frameinterval = 2\n",
        "image_sequence_len = 74\n",
        "character_categories = 28\n",
        "\n",
        "\n",
        "\n",
        "net_gen = NetGenerator(\n",
        "    input_shape=(image_sequence_len,image_shape[0],image_shape[1]//image_sequence_len//frameinterval,image_shape[2]), \n",
        "    out_categories=character_categories, \n",
        "    label_len=character_sequence_len_max\n",
        ")\n",
        "\n",
        "# very important or error\n",
        "K.clear_session()\n",
        "net_generator = net_gen.next()\n",
        "modelconfig=next(net_generator,None)\n",
        "  \n",
        "while modelconfig!=None:\n",
        "\n",
        "    modelname,model,test_func = modelconfig\n",
        "\n",
        "    print(modelname)\n",
        "    model.summary()\n",
        "    \n",
        "    train_gen = OCRBatchGenerator(train_texts, character_sequence_len_max, image_shape, image_sequence_len, frameinterval, steps=300, shuffle=True)\n",
        "    valid_gen = OCRBatchGenerator(validation_texts, character_sequence_len_max, image_shape, image_sequence_len, frameinterval, steps=33, shuffle=True)\n",
        "\n",
        "    cb_stat = StatCallback(\n",
        "        func = test_func,\n",
        "        validation_generator = valid_gen.next(), \n",
        "        validation_steps = 28\n",
        "    )\n",
        "    \n",
        "    cb_tensorboard = TensorBoard(\n",
        "        log_dir='./log/'+modelname,\n",
        "        histogram_freq=5,  \n",
        "        write_graph=True, \n",
        "        write_images=False,\n",
        "        write_grads=False,\n",
        "#         update_freq ='epoch'\n",
        "    )\n",
        "\n",
        "    cb_checkpoint = ModelCheckpoint(\n",
        "        './log/'+modelname+'_weights.h5', \n",
        "        monitor='cer', \n",
        "        verbose=0, \n",
        "        save_best_only=True, \n",
        "        save_weights_only=True, \n",
        "        mode='auto', \n",
        "        period=1\n",
        "    )\n",
        "\n",
        "    model.fit_generator(\n",
        "      initial_epoch = 0,\n",
        "      generator=train_gen.next(), \n",
        "      steps_per_epoch = train_gen.steps,\n",
        "      epochs = 200,\n",
        "      validation_data = next(valid_gen.next()), #in order to save histogram must not be generator, else can\n",
        "      validation_steps = valid_gen.steps,\n",
        "#       validation_freq = 1,\n",
        "      callbacks=[train_gen, valid_gen, cb_stat, cb_tensorboard, cb_checkpoint]\n",
        "    )\n",
        "    \n",
        "    # very important or error\n",
        "    K.clear_session()\n",
        "    modelconfig=next(net_generator,None)\n",
        "\n",
        "print('All done')\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.5\n",
            "1.15.0\n",
            "conv32-dense64-dense64-lr0.001\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "images (InputLayer)             (None, 74, 50, 5, 1) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding3d_1 (ZeroPadding3D (None, 76, 54, 9, 1) 0           images[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1 (Conv3D)               (None, 74, 25, 3, 32 2432        zero_padding3d_1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 74, 25, 3, 32 128         conv3d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 74, 25, 3, 32 0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling3d_1 (MaxPooling3D)  (None, 74, 12, 1, 32 0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_1 (TimeDistrib (None, 74, 384)      0           max_pooling3d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 74, 64)       24640       time_distributed_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 74, 64)       4160        dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 74, 28)       1820        dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 74, 28)       112         dense_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "y_pred (Activation)             (None, 74, 28)       0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "images_len (InputLayer)         (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "labels (InputLayer)             (None, 35)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "labels_len (InputLayer)         (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "ctc (Lambda)                    (None, 1)            0           y_pred[0][0]                     \n",
            "                                                                 images_len[0][0]                 \n",
            "                                                                 labels[0][0]                     \n",
            "                                                                 labels_len[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 33,292\n",
            "Trainable params: 33,172\n",
            "Non-trainable params: 120\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/1\n",
            "300/300 [==============================] - 47s 158ms/step - loss: 126.4756 - val_loss: 125.4906\n",
            "step 028, truth:[lay white in v seven now] decoded:[b ia in] raw:[b?????????????????????    iia                              i?????????????n]\n",
            "step 027, truth:[lay red in z nine please] decoded:[sniein] raw:[s???????????????niiiiiiiiiiiiiiiiiiiiiiiiiieiiiiiiiiii???????????????????n]\n",
            "step 026, truth:[bin white by t nine now] decoded:[b n] raw:[b????????????                                    ????????????????????????n]\n",
            "step 025, truth:[place green in d one now] decoded:[beenen] raw:[b???eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee?????e???????????n???????????een]\n",
            "step 024, truth:[bin white in u six soon] decoded:[baean] raw:[b????????????????????????????????aaaaaaeaaaaaaaaaaaaaaaaaaaaaaaaaaaaa????n]\n",
            "step 023, truth:[lay white which y one again] decoded:[s a n] raw:[s?????????????????????????????                                       aa ?n]\n",
            "step 022, truth:[bin red at p eight now] decoded:[ben] raw:[b????????????????????????eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee?????????????n]\n",
            "step 021, truth:[place red at m two now] decoded:[sin] raw:[s???????????????iiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiii??????????????????????n]\n",
            "step 020, truth:[bin green which x six now] decoded:[siaiaian] raw:[s???????????????iiiiiiiiiiiiiiiaiiiiiiiiiaiiiiiiiiiiiia??????????????????n]\n",
            "step 019, truth:[place blue in p four soon] decoded:[beneneneneeaibien] raw:[b???ee????n??e???ne?n?e??nne?eeaiiibiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiieen]\n",
            "step 018, truth:[set red which y two now] decoded:[b annen] raw:[b????????????????????                                     ????a???n?neee?n]\n",
            "step 017, truth:[bin white in z five again] decoded:[be a w] raw:[b??????????????????????????????????e               aaa                   w]\n",
            "step 016, truth:[set green which v eight please] decoded:[b n] raw:[b??????                                               ???????????????????n]\n",
            "step 015, truth:[lay white which g nine please] decoded:[snn] raw:[snnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnn??????????????????????????n]\n",
            "step 014, truth:[bin blue in n eight soon] decoded:[bin] raw:[b?????????????????????????iiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiii?????????n]\n",
            "step 013, truth:[place red at e seven now] decoded:[biain] raw:[b???????iiiiiiiiiiiiiiiiiiiiaiiiiiiiiiiiiiiiii???????????????????????????n]\n",
            "step 012, truth:[lay blue at a two again] decoded:[baanan] raw:[ba?a?nnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnn????a???????????????????????????n]\n",
            "step 011, truth:[place green which l three again] decoded:[bain] raw:[b????????????????aiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiii???????n]\n",
            "step 010, truth:[set red which y zero now] decoded:[bee iai ean] raw:[b????????e?ee???????????                     iai              ?e??????a?nn]\n",
            "step 009, truth:[lay blue at p nine please] decoded:[siain] raw:[s????????????????????????????????iiiiaaiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiii?n]\n",
            "step 008, truth:[lay blue in r six soon] decoded:[siain] raw:[s?????????????????????????iiiiiaiiiiiiiiiiiiiiiiiiiiiiiiiiiii????????????n]\n",
            "step 007, truth:[lay white in x two again] decoded:[s ia i n] raw:[s????????????????????????   iiia                   ii          ??????????n]\n",
            "step 006, truth:[place white by a four again] decoded:[bee e ln] raw:[b?e????eee????                          e               ????????l????????n]\n",
            "step 005, truth:[bin blue which n eight now] decoded:[b nea a  n] raw:[b?????????????????????????                      neea   a     ?     ??????n]\n",
            "step 004, truth:[place white which f eight now] decoded:[beeaiaianaean] raw:[b??eee????eaaaaaaaaaaaaaaaaaaaaaaaaaaaiaiaaaaaaaaaaaaaaa?n?a???????????ean]\n",
            "step 003, truth:[set blue by b six please] decoded:[bannee ennleen] raw:[b?aan?n?e???????e                                     ?eeen???nnnnleee?een]\n",
            "step 002, truth:[bin green which j zero please] decoded:[bieiain] raw:[b?iiiiiiiiiiiiiiieiiiiiiiiaaaiiiiiiiiiiiiiiiiii??????????????????????????n]\n",
            "step 001, truth:[set white in i zero again] decoded:[baeenenaaaeew] raw:[b?a????e?e?nnnnnennnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnn??????a?a??aaaee????ew]\n",
            "VAL_LOSS= 128.92474946521577 SER= 1.0 WER= 0.9952380952380953 CER= 0.6087755102040829\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:1265: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n",
            "\n",
            "conv32-dense64-bigru64-lr0.0005\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "images (InputLayer)             (None, 74, 50, 5, 1) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding3d_1 (ZeroPadding3D (None, 76, 54, 9, 1) 0           images[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1 (Conv3D)               (None, 74, 25, 3, 32 2432        zero_padding3d_1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 74, 25, 3, 32 128         conv3d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 74, 25, 3, 32 0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling3d_1 (MaxPooling3D)  (None, 74, 12, 1, 32 0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_1 (TimeDistrib (None, 74, 384)      0           max_pooling3d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 74, 64)       24640       time_distributed_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_1 (Bidirectional) (None, 74, 64)       49536       dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 74, 28)       1820        bidirectional_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 74, 28)       112         dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "y_pred (Activation)             (None, 74, 28)       0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "images_len (InputLayer)         (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "labels (InputLayer)             (None, 35)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "labels_len (InputLayer)         (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "ctc (Lambda)                    (None, 1)            0           y_pred[0][0]                     \n",
            "                                                                 images_len[0][0]                 \n",
            "                                                                 labels[0][0]                     \n",
            "                                                                 labels_len[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 78,668\n",
            "Trainable params: 78,548\n",
            "Non-trainable params: 120\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/1\n",
            "300/300 [==============================] - 90s 301ms/step - loss: 123.3653 - val_loss: 108.6954\n",
            "step 028, truth:[bin white by q eight again] decoded:[pla oaon] raw:[plaaaaaaa           ??????????????????????????????????????????oooooaaaaaon]\n",
            "step 027, truth:[bin blue which z six again] decoded:[pla oaon] raw:[plaaaaa??????????????????????????????????????????           oooooooaaaaoon]\n",
            "step 026, truth:[place green by d one again] decoded:[pla  oaon] raw:[plaaaaa        ??????????????????????????????????????????     ooooaaaaaoon]\n",
            "step 025, truth:[bin white which m nine again] decoded:[plae iaon] raw:[plaaaaeeee            iiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiaaaaaaaon]\n",
            "step 024, truth:[lay white which i zero now] decoded:[plae oaon] raw:[plaaaaeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee                  ooooooaaaaaaon]\n",
            "step 023, truth:[place white which f eight now] decoded:[plaehnaon] raw:[plaaaaeehhhhhhhhnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnaaaaaaaaon]\n",
            "step 022, truth:[set white by f two now] decoded:[plae ioaon] raw:[plaaaaeee                  iiiiiiiiiiiiiiiiiiiiiiiiiiiiii????oooaaaaaaaaon]\n",
            "step 021, truth:[lay white by r zero again] decoded:[pla aon] raw:[plaaaaa                           ????????????????????????????????????aaon]\n",
            "step 020, truth:[bin white in u six soon] decoded:[plac taon] raw:[plaaaaac                   tttttttttttttttttttttttttttttttttttttaaaaaaaaon]\n",
            "step 019, truth:[lay white in j eight please] decoded:[pla oaon] raw:[plaaaa???????????????????????????????????????????           ooooooaaaaaaon]\n",
            "step 018, truth:[lay white which d eight please] decoded:[plai oaon] raw:[plaaaaaiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiii        ooooaaaaaaaon]\n",
            "step 017, truth:[lay blue by g seven now] decoded:[plaa oaon] raw:[plaaaaa?a?????????????????????????????????????                 oooooaaaaon]\n",
            "step 016, truth:[lay red in q five again] decoded:[blaut oaon] raw:[blauuttttttttttttttttttttttttttttttt                          ooooaaaaaaon]\n",
            "step 015, truth:[set red by f four please] decoded:[place aon] raw:[plaaaaace                  ??????????????????????????????????????aaaaaaaon]\n",
            "step 014, truth:[bin white in p zero please] decoded:[plae oaon] raw:[plaaaeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee                ooooaaaaaaaon]\n",
            "step 013, truth:[set green by t zero now] decoded:[plac trt oaon] raw:[plaaaac     ttttttttttttttttttttrttttttttttttttttt           oooooaaaaaaon]\n",
            "step 012, truth:[lay white in v seven now] decoded:[plac tutaon] raw:[plaaaaac                    tttutttttttttttttttttttttttttttttttttaaaaaaaon]\n",
            "step 011, truth:[set white by g five soon] decoded:[placi oaon] raw:[plaaaccciiiiiiiiiiiiiiiiiiiiiiiiiiiiiiii                    oooooaaaaaaaon]\n",
            "step 010, truth:[lay red at o one please] decoded:[pla oaon] raw:[plaaa??????????????????????????????????                     oooooooaaaaaon]\n",
            "step 009, truth:[place white which i zero now] decoded:[plae iaon] raw:[plaaaaae                    iiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiaaaaaaaaaaon]\n",
            "step 008, truth:[lay blue in b five please] decoded:[plae oaon] raw:[plaaaaaeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee                    ooooooaaaaoon]\n",
            "step 007, truth:[place green at e two now] decoded:[pla oaon] raw:[plaaaaaaa????????????????????????????????????????              ooooaaaaaon]\n",
            "step 006, truth:[place white in d zero soon] decoded:[pla  oaon] raw:[plaaaaaa     ??????????????????????????????????????????       ooooaaaaaoon]\n",
            "step 005, truth:[set white which k three again] decoded:[pla e oaon] raw:[plaaaaa   eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee     oooaaaaaaaon]\n",
            "step 004, truth:[set red in d nine soon] decoded:[plac trtaon] raw:[plaaaac                           tttttttttttttttttttttrttttttttttaaaaaaon]\n",
            "step 003, truth:[bin green which v one again] decoded:[pla oaon] raw:[plaaa???????????????????????????????????????                   ooooaaaaaon]\n",
            "step 002, truth:[set green which v eight please] decoded:[placi oaon] raw:[plaaaaaciiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiii          oooooaaaaaaaon]\n",
            "step 001, truth:[set green which g four again] decoded:[placain oaon] raw:[plaaaccaiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiin                oooooaaaaaaon]\n",
            "VAL_LOSS= 105.14246244884673 SER= 1.0 WER= 0.9964285714285714 CER= 0.5674829931972808\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "conv32-dense64-tcn64k2d32-lr0.001\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "images (InputLayer)             (None, 74, 50, 5, 1) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding3d_1 (ZeroPadding3D (None, 76, 54, 9, 1) 0           images[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1 (Conv3D)               (None, 74, 25, 3, 32 2432        zero_padding3d_1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 74, 25, 3, 32 128         conv3d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 74, 25, 3, 32 0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling3d_1 (MaxPooling3D)  (None, 74, 12, 1, 32 0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_1 (TimeDistrib (None, 74, 384)      0           max_pooling3d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 74, 64)       24640       time_distributed_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_1 (Conv1D)               (None, 74, 64)       12352       dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_1 (Lambda)               (None, 74, 64)       0           conv1d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 74, 64)       0           lambda_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_2 (Conv1D)               (None, 74, 64)       12352       activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "lambda_2 (Lambda)               (None, 74, 64)       0           conv1d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 74, 64)       0           lambda_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 74, 64)       0           dense_1[0][0]                    \n",
            "                                                                 activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_3 (Conv1D)               (None, 74, 64)       12352       add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3 (Lambda)               (None, 74, 64)       0           conv1d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 74, 64)       0           lambda_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_4 (Conv1D)               (None, 74, 64)       12352       activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4 (Lambda)               (None, 74, 64)       0           conv1d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 74, 64)       0           lambda_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 74, 64)       0           add_1[0][0]                      \n",
            "                                                                 activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_5 (Conv1D)               (None, 74, 64)       12352       add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "lambda_5 (Lambda)               (None, 74, 64)       0           conv1d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 74, 64)       0           lambda_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_6 (Conv1D)               (None, 74, 64)       12352       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "lambda_6 (Lambda)               (None, 74, 64)       0           conv1d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 74, 64)       0           lambda_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 74, 64)       0           add_2[0][0]                      \n",
            "                                                                 activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 74, 28)       1820        add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 74, 28)       112         dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "y_pred (Activation)             (None, 74, 28)       0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "images_len (InputLayer)         (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "labels (InputLayer)             (None, 35)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "labels_len (InputLayer)         (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "ctc (Lambda)                    (None, 1)            0           y_pred[0][0]                     \n",
            "                                                                 images_len[0][0]                 \n",
            "                                                                 labels[0][0]                     \n",
            "                                                                 labels_len[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 103,244\n",
            "Trainable params: 103,124\n",
            "Non-trainable params: 120\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/1\n",
            "300/300 [==============================] - 49s 163ms/step - loss: 109.8620 - val_loss: 147.3324\n",
            "step 028, truth:[place white by n one soon] decoded:[pa blilte bwhip hphpspppasasw] raw:[ppaa  bblilte   bwwhiipppppp hphpppppppppppppspp?pppp??pppppaasasssssssssw]\n",
            "step 027, truth:[set green at p three please] decoded:[plbpipiepephph pspasw] raw:[pllbbbbpipieeppppephhphhhhhh     pppppss?pppppppppaaaaaaaaaaaaaaassssssssw]\n",
            "step 026, truth:[bin white which e eight please] decoded:[plbliepebwhp hp p pppasasw] raw:[pllbbbbbliieeppebwwwhhhhpp  hhhhhhpp p pppppp?p??pppppppppaaaaaaasaaaaaasw]\n",
            "step 025, truth:[bin red which s one now] decoded:[plab blie bwih pphpgpaisasn] raw:[plabb bbliiee   bwwwwwiihh   ppp??ppphhhpppppgppppaa?i???sssassssssssssssn]\n",
            "step 024, truth:[bin white in b six soon] decoded:[pabawpieph p sippssaposnsn] raw:[ppabawppiieeeeeepphhhhhh p       siii???p?p?ssss?saaaaposssssssnsssssssssn]\n",
            "step 023, truth:[bin white which v two now] decoded:[platb blite bw phphpapsn] raw:[platb bblitee   bwwwww     pppppppppppppppphpppphppaaaaapppppppssssssssssn]\n",
            "step 022, truth:[bin green which o three soon] decoded:[paphppphih p ppasn] raw:[paaaappphp??p?pphhhhihhhhh p    ???????p??ppppppaaaaaaaaassssssssssssssssn]\n",
            "step 021, truth:[place red at e nine soon] decoded:[platb blie bw wpapapapsasw] raw:[platb bbliiee   bwwwwwww   wppppppppppppppppppppaappaapappp??ssasssssssssw]\n",
            "step 020, truth:[set red in e one now] decoded:[plat bplte whp pasasw] raw:[platt bpllteee  wwwwwhhhpp  ppppppppppppppppppppppaaaaasssssassssssssssssw]\n",
            "step 019, truth:[set red at s four again] decoded:[pablite bw phphpapasas] raw:[ppabbbbbliite   bwwwwwww     ppppppppppppppppphphhhpappppppppppaasasssssss]\n",
            "step 018, truth:[set green by s five soon] decoded:[patc ble w p papse] raw:[ppatc bblllee   wwwwwww      pp ppppppppppppppppppppappppppppppsssssssssse]\n",
            "step 017, truth:[set green which b six again] decoded:[plap pipphwhih pppasn] raw:[pllapp piiipp???phwhhhih        ??p???pppp?pppppaaaaaaaaaaaasssssssssssssn]\n",
            "step 016, truth:[place white by r eight again] decoded:[plblie bw ppwhpapappse] raw:[pllbbbbbliiie   bwwwwwww       p?ppppppppppppppwhppappappppppp??ppppppppse]\n",
            "step 015, truth:[lay white in l zero now] decoded:[plablie bwp ptp ppspasasw] raw:[plabbbbbliiee   bwwwwwpppp  pppppppppppptpp ppp??ppppp???sppassssssssssasw]\n",
            "step 014, truth:[lay green in n four soon] decoded:[plblie bw sppwpapasse] raw:[pllbbbbbliiee   bwwwwwww        s??pp?pwppppppppppaaaaaaappaaas?ssssssssse]\n",
            "step 013, truth:[bin white at t seven now] decoded:[pat pblie w s ssphpapapse] raw:[ppat  pbllieee  wwwww         s s??sspppppppppppppppphpaaaaaapapssssssssse]\n",
            "step 012, truth:[bin white in g three soon] decoded:[pacpwplpipep h p p ppsasn] raw:[ppaccpwplpipepp hhhhhh p   p pp???????ppp????sssaaaaassssssssssssssssssssn]\n",
            "step 011, truth:[lay white which p two please] decoded:[plb wpiewphpwh sippasn] raw:[pllbb wpiiieew?pp?hpwwhhhhhh    s?i?p????????pppppaaaaaaaaaaaaaasssssssssn]\n",
            "step 010, truth:[set white in c seven please] decoded:[pabtblite w phapapapispspse] raw:[ppabtbbbliitee  wwwwwwww        ppppppppppppppphhaaaaaappappapp?isspssppse]\n",
            "step 009, truth:[lay green by g six soon] decoded:[plablite bw sphapahpapse] raw:[plabbbbbliite   bwwwwwww        s?pppppppppppppppphaaappahppapppssssssssse]\n",
            "step 008, truth:[place blue at i eight please] decoded:[pablie wp wpep p p psasasw] raw:[ppabbbbbliiie   wwwwwwwwp wppppepppppp ppppppp  pp ppppppppppppppssasaaasw]\n",
            "step 007, truth:[place white in u seven soon] decoded:[pab bliep bwhpephp pspspspsasasn] raw:[ppabb bbliieeep bwwhhhpppppeeppppppphpppppp psssppps??pspppppsasassssssssn]\n",
            "step 006, truth:[set red which d six soon] decoded:[pat blie w s phpapas] raw:[ppat  bbliieee  wwwwwwww      s ???pppppppppppppppphpppppapppppassssssssss]\n",
            "step 005, truth:[lay green in v zero now] decoded:[plablite bw papapse] raw:[plabbbbblitee   bwwwwwww        ?pppppppppppppppaaaaaaappaaaa???psssssssse]\n",
            "step 004, truth:[bin red which i five please] decoded:[plblitepwewphihph phpasn] raw:[pllbbbbblitepweewwphhihhpphhhhh  phhpppppppppppppppppaaaaaaaaaaaaaassssssn]\n",
            "step 003, truth:[place green by h four please] decoded:[pablie wiwhpspasase] raw:[ppaabbbbliieee  wwwwiiwhpppppppppppppppppppppp?spppppppppppppppaasssssaase]\n",
            "step 002, truth:[set green in f three please] decoded:[plablite pbwp pwptp p apasn] raw:[plabbbbbliite ppbwwwwwwwpppp  ppwppppppppptppp pp appppppppppppppasssssssn]\n",
            "step 001, truth:[place white by p nine soon] decoded:[pabliep w phapapapspsw] raw:[ppabbbbbliieeep wwwwwwww       pppppppppppppppppphaaappapppaapppssspsssssw]\n",
            "VAL_LOSS= 145.7688226609003 SER= 1.0 WER= 1.0 CER= 0.5793197278911577\n",
            "All done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8ZowvpY9Gz0o",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}